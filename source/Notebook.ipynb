{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from IPython import get_ipython\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import (accuracy_score, f1_score, make_scorer,\n",
    "                             precision_score, recall_score)\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sqlalchemy import select\n",
    "\n",
    "from custom_transfomers.date_window import TimeWindowTransformer\n",
    "from data_base.connection import session\n",
    "from data_base.models import models\n",
    "from project_utils.data_manipulation import generate_aggregation"
   ]
  },
  {
   "source": [
    "## Construção do dataframe utilizando buscas no banco de dados sql\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ]
  },
  {
   "source": [
    "query = select(\n",
    "    models.Variables.date,\n",
    "    models.Variables.precipitation.label('precipitation'),\n",
    "    models.Variables.temperature.label('temperature'),\n",
    "    models.Variables.evaporation.label('evaporation'),\n",
    "    models.Variables.surface_runoff.label('surface_runoff'),\n",
    "    models.Coordinate.river_id.label('river'),    \n",
    "    models.Reservoir.level,\n",
    "    models.Reservoir.streamflow\n",
    ").\\\n",
    "    join(models.Variables.coordinate).\\\n",
    "    join(models.Reservoir, models.Variables.date == models.Reservoir.date)\n",
    "\n",
    "RawDataFrame = pandas.read_sql(query, session.bind)\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 21,
   "outputs": []
  },
  {
   "source": [
    "# DataFrame consolidado porém com os atributos para cada rio posicionados em uma diferente coluna\n",
    "ConsolidatedDataFrame = (\n",
    "    RawDataFrame.\n",
    "    groupby(['date', 'river', 'level', 'streamflow']).\n",
    "    agg({\n",
    "        'precipitation': 'sum',\n",
    "        'evaporation': 'sum',\n",
    "        'temperature': 'mean',\n",
    "        'surface_runoff':'mean',\n",
    "    }).\n",
    "    reset_index().\n",
    "    pivot(index=[\"date\", 'level', 'streamflow'], columns=\"river\")\n",
    ")\n",
    "\n",
    "ConsolidatedDataFrame.insert(0,'previous_streamflow', pandas.DataFrame(ConsolidatedDataFrame.index.get_level_values('streamflow')).shift(1).values)\n",
    "ConsolidatedDataFrame.insert(0,'previous_level', pandas.DataFrame(ConsolidatedDataFrame.index.get_level_values('level')).shift(1).values)\n",
    "\n",
    "ConsolidatedDataFrame = ConsolidatedDataFrame.dropna()\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "rivers = session.query(models.River).all()\n",
    "\n",
    "precipitation_agg = generate_aggregation('sum', 'precipitation', [river.id for river in rivers])\n",
    "evaporation_agg = generate_aggregation('sum', 'evaporation', [river.id for river in rivers])\n",
    "temperature_agg = generate_aggregation('mean', 'temperature', [river.id for river in rivers])\n",
    "runoff_agg = generate_aggregation('mean', 'surface_runoff', [river.id for river in rivers])\n",
    "\n",
    "cols = ['precipitation', 'evaporation', 'temperature', 'surface_runoff']\n",
    "\n",
    "agg = precipitation_agg\n",
    "agg.update(evaporation_agg)\n",
    "agg.update(temperature_agg)\n",
    "agg.update(runoff_agg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_params = dict(\n",
    "    estimator=Pipeline([\n",
    "                ('windowing', TimeWindowTransformer(columns=cols)),\n",
    "                ('imputer', SimpleImputer(strategy='mean')),\n",
    "                ('scaler', MinMaxScaler(feature_range=(0, 1))),\n",
    "                ('clf', DummyRegressor())\n",
    "            ]), \n",
    "            param_grid=[\n",
    "                {\n",
    "                    'windowing__aggregate': [agg],\n",
    "                    'windowing__rolling': range(1, 32, 10),\n",
    "                    'windowing__dropna': [False],\n",
    "                    'clf': (\n",
    "                        TransformedTargetRegressor(\n",
    "                        transformer=MinMaxScaler(feature_range=(0, 1)), \n",
    "                        regressor=SVR(cache_size=1000)\n",
    "                    ),),\n",
    "                    'clf__regressor__C': range(1, 15, 3),\n",
    "                    'clf__regressor__gamma': ['auto', 'scale'],\n",
    "                    'clf__regressor__kernel': ['rbf']\n",
    "                },\n",
    "                {\n",
    "                    'windowing__aggregate': [agg],\n",
    "                    'windowing__rolling': range(1, 32, 10),\n",
    "                    'windowing__dropna': [False],\n",
    "                    'clf': (RandomForestRegressor(), ),\n",
    "                    'clf__random_state': [seed],\n",
    "                    'clf__n_estimators': [200]\n",
    "                },\n",
    "                {\n",
    "                    'windowing__aggregate': [agg],\n",
    "                    'windowing__rolling': range(1, 32, 10),\n",
    "                    'windowing__dropna': [False],\n",
    "                    'clf': (DecisionTreeRegressor(), ),\n",
    "                    'clf__random_state': [seed]\n",
    "                },\n",
    "                {\n",
    "                    'windowing__aggregate': [agg],\n",
    "                    'windowing__rolling': range(1, 32, 10),\n",
    "                    'windowing__dropna': [False],\n",
    "                    'clf': (StackingRegressor(\n",
    "                        estimators=[('RandomForest', RandomForestRegressor()), ('SVR', SVR())], \n",
    "                        final_estimator=Ridge()\n",
    "                    ),),\n",
    "                    'clf__RandomForest__random_state': [seed],\n",
    "                    'clf__RandomForest__n_estimators': [200],\n",
    "                }\n",
    "            ],\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            cv=10,\n",
    "            n_jobs=-1,\n",
    "            verbose=10,\n",
    "            error_score='raise'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['level', 'streamflow']\n",
    "\n",
    "clf_search = {target: GridSearchCV(**grid_search_params) for target in targets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamflow_X_train, streamflow_X_test, streamflow_y_train, streamflow_y_test = train_test_split(\n",
    "     ConsolidatedDataFrame,\n",
    "     ConsolidatedDataFrame.index.get_level_values('streamflow'), random_state=seed\n",
    ")\n",
    "\n",
    "level_X_train, level_X_test, level_y_train, level_y_test = train_test_split(\n",
    "     ConsolidatedDataFrame,\n",
    "     ConsolidatedDataFrame.index.get_level_values('level'), random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 52 candidates, totalling 520 fits\n",
      "Fitting 10 folds for each of 52 candidates, totalling 520 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "             estimator=Pipeline(steps=[('windowing',\n",
       "                                        TimeWindowTransformer(columns=['precipitation',\n",
       "                                                                       'evaporation',\n",
       "                                                                       'temperature',\n",
       "                                                                       'surface_runoff'])),\n",
       "                                       ('imputer', SimpleImputer()),\n",
       "                                       ('scaler', MinMaxScaler()),\n",
       "                                       ('clf', DummyRegressor())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'clf': (TransformedTargetRegressor(regressor=SVR(cache_size=1000),\n",
       "                                                             transfor...\n",
       "                                                    ('precipitation', 11): 'sum',\n",
       "                                                    ('surface_runoff', 1): 'mean',\n",
       "                                                    ('surface_runoff', 2): 'mean',\n",
       "                                                    ('surface_runoff', 3): 'mean',\n",
       "                                                    ('surface_runoff', 4): 'mean',\n",
       "                                                    ('surface_runoff', 5): 'mean',\n",
       "                                                    ('surface_runoff', 6): 'mean',\n",
       "                                                    ('surface_runoff', 7): 'mean',\n",
       "                                                    ('surface_runoff', 8): 'mean', ...}],\n",
       "                          'windowing__dropna': [False],\n",
       "                          'windowing__rolling': range(1, 32, 10)}],\n",
       "             scoring='neg_root_mean_squared_error', verbose=10)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "level_classifier = clf_search['level']\n",
    "streamflow_classifier = clf_search['streamflow']\n",
    "\n",
    "streamflow_classifier.fit(streamflow_X_train, streamflow_y_train) \n",
    "level_classifier.fit(level_X_train, level_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame()\n",
    "df['level'] = level_y_test\n",
    "df['p_level'] = level_classifier.predict(level_X_test)\n",
    "df['streamflow'] = streamflow_y_test\n",
    "df['p_streamflow'] = streamflow_classifier.predict(streamflow_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{TransformedTargetRegressor(regressor=SVR(cache_size=1000),\n",
       "                            transformer=MinMaxScaler()): (-0.8119226320006565,\n",
       "  0.2517460605099128),\n",
       " DecisionTreeRegressor(): (-0.0945240360557121, 0.011127606616660493),\n",
       " RandomForestRegressor(): (-0.07131128271845194, 0.011784351816806203),\n",
       " StackingRegressor(estimators=[('RandomForest',\n",
       "                                RandomForestRegressor(n_estimators=200,\n",
       "                                                      random_state=0)),\n",
       "                               ('SVR', SVR())],\n",
       "                   final_estimator=Ridge()): (-0.07000870211637965,\n",
       "  0.011455767344408707)}"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "level_results = pandas.DataFrame(level_classifier.cv_results_).sort_values('rank_test_score', ascending=False)\n",
    "{result['param_clf']: (result['mean_test_score'], result['std_test_score']) for _, result in level_results.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{TransformedTargetRegressor(regressor=SVR(cache_size=1000),\n",
       "                            transformer=MinMaxScaler()): (-273.61219949197346,\n",
       "  42.00820998338783),\n",
       " DecisionTreeRegressor(): (-321.6893662727692, 45.29511261095428),\n",
       " RandomForestRegressor(): (-239.50962151368032, 49.860474503472595),\n",
       " StackingRegressor(estimators=[('RandomForest',\n",
       "                                RandomForestRegressor(n_estimators=200,\n",
       "                                                      random_state=0)),\n",
       "                               ('SVR', SVR())],\n",
       "                   final_estimator=Ridge()): (-238.8529314528661,\n",
       "  49.800020142710984)}"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "streamflow_results = pandas.DataFrame(streamflow_classifier.cv_results_).sort_values('rank_test_score', ascending=False)\n",
    "{result['param_clf']: (result['mean_test_score'], result['std_test_score']) for _, result in streamflow_results.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      level     p_level  streamflow  p_streamflow\n",
       "0    557.06  557.076007      115.78    114.291984\n",
       "1    561.52  561.423564     1881.78   2253.167742\n",
       "2    560.47  560.525260      179.39    168.495383\n",
       "3    559.26  559.117543     2123.00    901.570480\n",
       "4    564.53  564.174552     2540.00   2189.446958\n",
       "..      ...         ...         ...           ...\n",
       "622  568.56  568.589757      351.00    335.441393\n",
       "623  560.23  560.218557      239.00    326.239235\n",
       "624  557.55  557.565049      100.00     98.276586\n",
       "625  562.87  562.917312     1851.35   2161.692424\n",
       "626  559.58  559.571148      121.00    131.260700\n",
       "\n",
       "[627 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level</th>\n      <th>p_level</th>\n      <th>streamflow</th>\n      <th>p_streamflow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>557.06</td>\n      <td>557.076007</td>\n      <td>115.78</td>\n      <td>114.291984</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>561.52</td>\n      <td>561.423564</td>\n      <td>1881.78</td>\n      <td>2253.167742</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>560.47</td>\n      <td>560.525260</td>\n      <td>179.39</td>\n      <td>168.495383</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>559.26</td>\n      <td>559.117543</td>\n      <td>2123.00</td>\n      <td>901.570480</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>564.53</td>\n      <td>564.174552</td>\n      <td>2540.00</td>\n      <td>2189.446958</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>622</th>\n      <td>568.56</td>\n      <td>568.589757</td>\n      <td>351.00</td>\n      <td>335.441393</td>\n    </tr>\n    <tr>\n      <th>623</th>\n      <td>560.23</td>\n      <td>560.218557</td>\n      <td>239.00</td>\n      <td>326.239235</td>\n    </tr>\n    <tr>\n      <th>624</th>\n      <td>557.55</td>\n      <td>557.565049</td>\n      <td>100.00</td>\n      <td>98.276586</td>\n    </tr>\n    <tr>\n      <th>625</th>\n      <td>562.87</td>\n      <td>562.917312</td>\n      <td>1851.35</td>\n      <td>2161.692424</td>\n    </tr>\n    <tr>\n      <th>626</th>\n      <td>559.58</td>\n      <td>559.571148</td>\n      <td>121.00</td>\n      <td>131.260700</td>\n    </tr>\n  </tbody>\n</table>\n<p>627 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5  ('.env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "e01c415138263b81e74f4b8560efc462ff3e43faa8a63c42675b82c8ccb72528"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}