{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from IPython import get_ipython\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import (accuracy_score, f1_score, make_scorer,\n",
    "                             precision_score, recall_score)\n",
    "from sklearn.model_selection import (GridSearchCV, KFold, cross_val_score,\n",
    "                                     train_test_split)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sqlalchemy import select\n",
    "\n",
    "from custom_transfomers.date_window import TimeWindowTransformer\n",
    "from data_base.connection import session\n",
    "from data_base.models import models\n",
    "from project_utils.data_manipulation import generate_aggregation"
   ]
  },
  {
   "source": [
    "## Construção do dataframe utilizando buscas no banco de dados sql\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "source": [
    "query = select(\n",
    "    models.Variables.date,\n",
    "    models.Variables.precipitation.label('precipitation'),\n",
    "    models.Variables.temperature.label('temperature'),\n",
    "    models.Variables.evaporation.label('evaporation'),\n",
    "    models.Variables.surface_runoff.label('surface_runoff'),\n",
    "    models.Coordinate.river_id.label('river'),    \n",
    "    models.Reservoir.level,\n",
    "    models.Reservoir.streamflow\n",
    ").\\\n",
    "    join(models.Variables.coordinate).\\\n",
    "    join(models.Reservoir, models.Variables.date == models.Reservoir.date)\n",
    "\n",
    "RawDataFrame = pandas.read_sql(query, session.bind)\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "source": [
    "# DataFrame consolidado porém com os atributos para cada rio posicionados em uma diferente coluna\n",
    "ConsolidatedDataFrame = (\n",
    "    RawDataFrame.\n",
    "    groupby(['date', 'river', 'level', 'streamflow']).\n",
    "    agg({\n",
    "        'precipitation': 'sum',\n",
    "        'evaporation': 'sum',\n",
    "        'temperature': 'mean',\n",
    "        'surface_runoff':'mean',\n",
    "    }).\n",
    "    reset_index().\n",
    "    pivot(index=[\"date\", 'level', 'streamflow'], columns=\"river\")\n",
    ")\n",
    "\n",
    "ConsolidatedDataFrame.insert(0,'previous_streamflow', pandas.DataFrame(ConsolidatedDataFrame.index.get_level_values('streamflow')).shift(1).values)\n",
    "ConsolidatedDataFrame.insert(0,'previous_level', pandas.DataFrame(ConsolidatedDataFrame.index.get_level_values('level')).shift(1).values)\n",
    "\n",
    "ConsolidatedDataFrame = ConsolidatedDataFrame.dropna()\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "rivers = session.query(models.River).all()\n",
    "\n",
    "precipitation_agg = generate_aggregation('sum', 'precipitation', [river.id for river in rivers])\n",
    "evaporation_agg = generate_aggregation('sum', 'evaporation', [river.id for river in rivers])\n",
    "temperature_agg = generate_aggregation('mean', 'temperature', [river.id for river in rivers])\n",
    "runoff_agg = generate_aggregation('mean', 'surface_runoff', [river.id for river in rivers])\n",
    "\n",
    "cols = ['precipitation', 'evaporation', 'temperature', 'surface_runoff']\n",
    "\n",
    "agg = precipitation_agg\n",
    "agg.update(evaporation_agg)\n",
    "agg.update(temperature_agg)\n",
    "agg.update(runoff_agg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_params = dict(\n",
    "    estimator=Pipeline([\n",
    "                ('windowing', TimeWindowTransformer(columns=cols)),\n",
    "                ('imputer', SimpleImputer(strategy='mean')),\n",
    "                ('scaler', MinMaxScaler(feature_range=(0, 1))),\n",
    "                ('clf', DummyRegressor())\n",
    "            ]), \n",
    "            param_grid=[\n",
    "                {\n",
    "                    'windowing__aggregate': [agg],\n",
    "                    'windowing__rolling': range(1, 32, 10),\n",
    "                    'windowing__dropna': [False],\n",
    "                    'clf': [TransformedTargetRegressor(\n",
    "                                transformer=MinMaxScaler(feature_range=(0, 1)), \n",
    "                                regressor=SVR(cache_size=1000)\n",
    "                            )],\n",
    "                    'clf__regressor__C': range(1, 15, 3),\n",
    "                    'clf__regressor__gamma': ['auto', 'scale'],\n",
    "                    'clf__regressor__kernel': ['rbf']\n",
    "                },\n",
    "                {\n",
    "                    'windowing__aggregate': [agg],\n",
    "                    'windowing__rolling': range(1, 32, 10),\n",
    "                    'windowing__dropna': [False],\n",
    "                    'clf': (RandomForestRegressor(),),\n",
    "                    'clf__random_state': [seed],\n",
    "                    'clf__n_estimators': [200]\n",
    "                },\n",
    "                {\n",
    "                    'windowing__aggregate': [agg],\n",
    "                    'windowing__rolling': range(1, 32, 10),\n",
    "                    'windowing__dropna': [False],\n",
    "                    'clf': (DecisionTreeRegressor(), ),\n",
    "                    'clf__random_state': [seed]\n",
    "                },\n",
    "                {\n",
    "                    'windowing__aggregate': [agg],\n",
    "                    'windowing__rolling': range(1, 32, 10),\n",
    "                    'windowing__dropna': [False],\n",
    "                    'clf': (StackingRegressor(\n",
    "                        estimators=[('RandomForest', RandomForestRegressor()), ('SVR', SVR())], \n",
    "                        final_estimator=Ridge()\n",
    "                    ),),\n",
    "                    'clf__RandomForest__random_state': [seed],\n",
    "                    'clf__RandomForest__n_estimators': [200],\n",
    "                }\n",
    "            ],\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            cv=10,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 52 candidates, totalling 520 fits\n",
      "Fitting 10 folds for each of 52 candidates, totalling 520 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('windowing',\n",
       "                                        TimeWindowTransformer(columns=['precipitation',\n",
       "                                                                       'evaporation',\n",
       "                                                                       'temperature',\n",
       "                                                                       'surface_runoff'])),\n",
       "                                       ('imputer', SimpleImputer()),\n",
       "                                       ('scaler', MinMaxScaler()),\n",
       "                                       ('clf', DummyRegressor())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'clf': [TransformedTargetRegressor(regressor=SVR(cache_size=1000),\n",
       "                                                             transformer=MinMaxScaler())]...\n",
       "                                                    ('precipitation', 11): 'sum',\n",
       "                                                    ('surface_runoff', 1): 'mean',\n",
       "                                                    ('surface_runoff', 2): 'mean',\n",
       "                                                    ('surface_runoff', 3): 'mean',\n",
       "                                                    ('surface_runoff', 4): 'mean',\n",
       "                                                    ('surface_runoff', 5): 'mean',\n",
       "                                                    ('surface_runoff', 6): 'mean',\n",
       "                                                    ('surface_runoff', 7): 'mean',\n",
       "                                                    ('surface_runoff', 8): 'mean', ...}],\n",
       "                          'windowing__dropna': [False],\n",
       "                          'windowing__rolling': range(1, 32, 10)}],\n",
       "             scoring='neg_root_mean_squared_error', verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "targets = ['level', 'streamflow']\n",
    "\n",
    "clf_search = {target: GridSearchCV(**grid_search_params) for target in targets}\n",
    "\n",
    "level_estimator_search = clf_search['level']\n",
    "streamflow_estimator_search = clf_search['streamflow']\n",
    "\n",
    "level_estimator_search.fit(ConsolidatedDataFrame, ConsolidatedDataFrame.index.get_level_values('level'))\n",
    "streamflow_estimator_search.fit(ConsolidatedDataFrame, ConsolidatedDataFrame.index.get_level_values('streamflow')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_X_train, level_X_test, level_y_train, level_y_test = train_test_split(\n",
    "     ConsolidatedDataFrame,\n",
    "     ConsolidatedDataFrame.index.get_level_values('level'), random_state=seed\n",
    ")\n",
    "\n",
    "streamflow_X_train, streamflow_X_test, streamflow_y_train, streamflow_y_test = train_test_split(\n",
    "     ConsolidatedDataFrame,\n",
    "     ConsolidatedDataFrame.index.get_level_values('streamflow'), random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('windowing',\n",
       "                 TimeWindowTransformer(aggregate={('evaporation', 1): 'sum',\n",
       "                                                  ('evaporation', 2): 'sum',\n",
       "                                                  ('evaporation', 3): 'sum',\n",
       "                                                  ('evaporation', 4): 'sum',\n",
       "                                                  ('evaporation', 5): 'sum',\n",
       "                                                  ('evaporation', 6): 'sum',\n",
       "                                                  ('evaporation', 7): 'sum',\n",
       "                                                  ('evaporation', 8): 'sum',\n",
       "                                                  ('evaporation', 9): 'sum',\n",
       "                                                  ('evaporation', 10): 'sum',\n",
       "                                                  ('evaporation', 11): 'sum',\n",
       "                                                  ('precipitation', 1): 's...\n",
       "                                                  ('surface_runoff', 6): 'mean',\n",
       "                                                  ('surface_runoff', 7): 'mean',\n",
       "                                                  ('surface_runoff', 8): 'mean', ...},\n",
       "                                       columns=['precipitation', 'evaporation',\n",
       "                                                'temperature',\n",
       "                                                'surface_runoff'])),\n",
       "                ('imputer', SimpleImputer()), ('scaler', MinMaxScaler()),\n",
       "                ('clf',\n",
       "                 StackingRegressor(estimators=[('RandomForest',\n",
       "                                                RandomForestRegressor(n_estimators=200,\n",
       "                                                                      random_state=0)),\n",
       "                                               ('SVR', SVR())],\n",
       "                                   final_estimator=Ridge()))])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "level_estimator = level_estimator_search.best_estimator_\n",
    "streamflow_estimator = streamflow_estimator_search.best_estimator_\n",
    "\n",
    "level_estimator.fit(level_X_train, level_y_train)\n",
    "streamflow_estimator.fit(streamflow_X_train, streamflow_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.1s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.1s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    2.1s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.1213866 , -0.08497091, -0.08873553, -0.11335988, -0.10027779,\n",
       "       -0.07876949, -0.11725681, -0.09109943, -0.07495576, -0.09863412])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "cross_val_score(\n",
    "    level_estimator,\n",
    "    level_X_test, level_y_test,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    "    verbose=10,\n",
    "    error_score='raise'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:   11.8s remaining:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:   11.8s remaining:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   11.9s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   11.9s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-256.32621209, -180.26168467, -269.47444049, -345.59480365,\n",
       "       -181.4729543 , -173.52005328, -194.35490686, -176.77016017,\n",
       "       -163.78047923, -284.31228502])"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "cross_val_score(\n",
    "    streamflow_estimator,\n",
    "    streamflow_X_test, streamflow_y_test,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    "    verbose=10,\n",
    "    error_score='raise'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame()\n",
    "df['level'] = level_y_test\n",
    "df['p_level'] = level_estimator.predict(level_X_test)\n",
    "df['streamflow'] = streamflow_y_test\n",
    "df['p_streamflow'] = streamflow_estimator.predict(streamflow_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      level    p_level  streamflow  p_streamflow\n",
       "0    557.06  557.08795      115.78    114.291984\n",
       "1    561.52  561.41170     1881.78   2253.167742\n",
       "2    560.47  560.50315      179.39    168.495383\n",
       "3    559.26  559.11960     2123.00    901.570480\n",
       "4    564.53  564.16450     2540.00   2189.446958\n",
       "..      ...        ...         ...           ...\n",
       "622  568.56  568.55825      351.00    335.441393\n",
       "623  560.23  560.22980      239.00    326.239235\n",
       "624  557.55  557.57775      100.00     98.276586\n",
       "625  562.87  562.83485     1851.35   2161.692424\n",
       "626  559.58  559.55210      121.00    131.260700\n",
       "\n",
       "[627 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level</th>\n      <th>p_level</th>\n      <th>streamflow</th>\n      <th>p_streamflow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>557.06</td>\n      <td>557.08795</td>\n      <td>115.78</td>\n      <td>114.291984</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>561.52</td>\n      <td>561.41170</td>\n      <td>1881.78</td>\n      <td>2253.167742</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>560.47</td>\n      <td>560.50315</td>\n      <td>179.39</td>\n      <td>168.495383</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>559.26</td>\n      <td>559.11960</td>\n      <td>2123.00</td>\n      <td>901.570480</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>564.53</td>\n      <td>564.16450</td>\n      <td>2540.00</td>\n      <td>2189.446958</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>622</th>\n      <td>568.56</td>\n      <td>568.55825</td>\n      <td>351.00</td>\n      <td>335.441393</td>\n    </tr>\n    <tr>\n      <th>623</th>\n      <td>560.23</td>\n      <td>560.22980</td>\n      <td>239.00</td>\n      <td>326.239235</td>\n    </tr>\n    <tr>\n      <th>624</th>\n      <td>557.55</td>\n      <td>557.57775</td>\n      <td>100.00</td>\n      <td>98.276586</td>\n    </tr>\n    <tr>\n      <th>625</th>\n      <td>562.87</td>\n      <td>562.83485</td>\n      <td>1851.35</td>\n      <td>2161.692424</td>\n    </tr>\n    <tr>\n      <th>626</th>\n      <td>559.58</td>\n      <td>559.55210</td>\n      <td>121.00</td>\n      <td>131.260700</td>\n    </tr>\n  </tbody>\n</table>\n<p>627 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5  ('.env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "e01c415138263b81e74f4b8560efc462ff3e43faa8a63c42675b82c8ccb72528"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}