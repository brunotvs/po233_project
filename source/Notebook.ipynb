{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from IPython import get_ipython\n",
    "from sklearn import tree\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import (accuracy_score, f1_score, make_scorer,\n",
    "                             precision_score, recall_score)\n",
    "from sklearn.model_selection import (GridSearchCV, KFold, cross_val_score,\n",
    "                                     train_test_split)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sqlalchemy import select\n",
    "\n",
    "from custom_transfomers.date_window import TimeWindowTransformer, Debug\n",
    "from data_base.connection import session\n",
    "from data_base.models import models\n",
    "from project_utils.data_manipulation import generate_aggregation"
   ]
  },
  {
   "source": [
    "## Construção do dataframe utilizando buscas no banco de dados sql\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "query = select(\n",
    "    models.Variables.date,\n",
    "    models.Variables.precipitation.label('precipitation'),\n",
    "    models.Variables.temperature.label('temperature'),\n",
    "    models.Variables.evaporation.label('evaporation'),\n",
    "    models.Variables.surface_runoff.label('surface_runoff'),\n",
    "    models.Coordinate.river_id.label('river'),\n",
    "    models.Reservoir.level,\n",
    "    models.Reservoir.streamflow\n",
    ").\\\n",
    "    join(models.Variables.coordinate).\\\n",
    "    join(models.Reservoir, models.Variables.date == models.Reservoir.date)\n",
    "\n",
    "RawDataFrame = pandas.read_sql(query, session.bind)\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# DataFrame consolidado porém com os atributos para cada rio posicionados em uma diferente coluna\n",
    "ConsolidatedDataFrame = (\n",
    "    RawDataFrame.\n",
    "    groupby(['date', 'level', 'river', 'streamflow']).\n",
    "    agg({\n",
    "        'precipitation': 'sum',\n",
    "        'evaporation': 'sum',\n",
    "        'temperature': 'mean',\n",
    "        'surface_runoff': 'mean',\n",
    "    }).\n",
    "    reset_index().\n",
    "    pivot(index=[\"date\", 'level', 'streamflow'], columns=\"river\")\n",
    ")\n",
    "\n",
    "ConsolidatedDataFrame.insert(0, 'previous_streamflow', pandas.DataFrame(\n",
    "    ConsolidatedDataFrame.index.get_level_values('streamflow')).shift(1).values)\n",
    "ConsolidatedDataFrame.insert(0, 'previous_level', pandas.DataFrame(\n",
    "    ConsolidatedDataFrame.index.get_level_values('level')).shift(1).values)\n",
    "\n",
    "ConsolidatedDataFrame = ConsolidatedDataFrame.dropna()\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "rivers = session.query(models.River).all()\n",
    "\n",
    "precipitation_agg = generate_aggregation('sum', 'precipitation', [river.id for river in rivers])\n",
    "evaporation_agg = generate_aggregation('sum', 'evaporation', [river.id for river in rivers])\n",
    "temperature_agg = generate_aggregation('mean', 'temperature', [river.id for river in rivers])\n",
    "runoff_agg = generate_aggregation('mean', 'surface_runoff', [river.id for river in rivers])\n",
    "\n",
    "cols = ['precipitation', 'evaporation', 'temperature', 'surface_runoff']\n",
    "\n",
    "agg = precipitation_agg\n",
    "agg.update(evaporation_agg)\n",
    "agg.update(temperature_agg)\n",
    "agg.update(runoff_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "\n",
    "windowing_params = {\n",
    "    'windowing__aggregate': [agg],\n",
    "    'windowing__rolling': range(1, 32, 10),\n",
    "    'windowing__dropna': [False],\n",
    "}\n",
    "\n",
    "grid_search_params = dict(\n",
    "    estimator=Pipeline(\n",
    "        [\n",
    "            ('windowing', TimeWindowTransformer(columns=cols)),\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', MinMaxScaler(feature_range=(0, 1))),\n",
    "            ('clf', DummyRegressor())\n",
    "        ]\n",
    "    ),\n",
    "    param_grid=[\n",
    "        {\n",
    "            **windowing_params,\n",
    "            'clf': [TransformedTargetRegressor(\n",
    "                regressor=SVR(cache_size=1000)\n",
    "            )],\n",
    "            'clf__transformer': [MinMaxScaler(feature_range=(0, 1))],\n",
    "            'clf__regressor__C': range(1, 15, 3),\n",
    "            'clf__regressor__gamma': ['auto', 'scale'],\n",
    "            'clf__regressor__kernel': ['rbf']\n",
    "        },\n",
    "        {\n",
    "            **windowing_params,\n",
    "            'scaler': [MinMaxScaler(), None],\n",
    "            'clf': [TransformedTargetRegressor(\n",
    "                regressor=RandomForestRegressor()\n",
    "            )],\n",
    "            'clf__transformer': [MinMaxScaler(feature_range=(0, 1)), None],\n",
    "            'clf__regressor__random_state': [seed],\n",
    "            'clf__regressor__n_estimators': [200],\n",
    "        },\n",
    "        {\n",
    "            **windowing_params,\n",
    "            'clf': (DecisionTreeRegressor(), ),\n",
    "            'clf__random_state': [seed]\n",
    "        },\n",
    "        {\n",
    "            **windowing_params,\n",
    "            'clf': (StackingRegressor(\n",
    "                estimators=[\n",
    "                    ('RandomForest', RandomForestRegressor()),\n",
    "                    ('SVR', TransformedTargetRegressor(\n",
    "                        transformer=MinMaxScaler(feature_range=(0, 1)),\n",
    "                        regressor=SVR()\n",
    "                    ))\n",
    "                ],\n",
    "                final_estimator=TransformedTargetRegressor(\n",
    "                    transformer=MinMaxScaler(feature_range=(0, 1)),\n",
    "                    regressor=SVR()\n",
    "                )\n",
    "            ),),\n",
    "            'clf__RandomForest__random_state': [seed],\n",
    "            'clf__RandomForest__n_estimators': [200],\n",
    "            'clf__SVR__regressor__C': range(1, 16, 5),\n",
    "            'clf__final_estimator__regressor__C': range(1, 16, 5)\n",
    "        }\n",
    "    ],\n",
    "    scoring='r2',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    error_score='raise'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['level', 'streamflow']\n",
    "\n",
    "clf_search = {target: GridSearchCV(**grid_search_params) for target in targets}\n",
    "\n",
    "clf_search['level'].fit(ConsolidatedDataFrame, ConsolidatedDataFrame.index.get_level_values('level'))\n",
    "clf_search['streamflow'].fit(ConsolidatedDataFrame, ConsolidatedDataFrame.index.get_level_values('streamflow'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{clf_search['level'].best_score_} ± {clf_search['level'].cv_results_['std_test_score'][clf_search['level'].best_index_]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{clf_search['streamflow'].best_score_} ± {clf_search['streamflow'].cv_results_['std_test_score'][clf_search['streamflow'].best_index_]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_estimator = clf_search['level'].best_estimator_\n",
    "print(f\"level score: {level_cv_score.mean()} +- {level_cv_score.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamflow_estimator = clf_search['streamflow'].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pandas.DataFrame()\n",
    "full_df['level'] = ConsolidatedDataFrame.index.get_level_values('level')\n",
    "full_df['p_level'] = level_estimator.predict(ConsolidatedDataFrame)\n",
    "full_df['streamflow'] = ConsolidatedDataFrame.index.get_level_values('streamflow')\n",
    "full_df['p_streamflow'] = streamflow_estimator.predict(ConsolidatedDataFrame)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5  ('.env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "e01c415138263b81e74f4b8560efc462ff3e43faa8a63c42675b82c8ccb72528"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}